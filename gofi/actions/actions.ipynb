{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877f4837",
   "metadata": {},
   "source": [
    "# Iskanje delovanj\n",
    "V tem dokumentu predstavim uporabo diferencialnih enačb za iskanje delovanj in avtomorfizmov grafov.\n",
    "\n",
    "## Delovanja\n",
    "Iščemo model za homomorfizme $G=<S|R> \\to S_n$. Naivno bi lahko vsak generator $s$ slikali v poljubno tabelo $\\rho(s) = \\begin{pmatrix} \n",
    "1 & 2 & \\cdots & n \\\\\n",
    "1^s & 2^s & \\cdots & n^s \n",
    "\\end{pmatrix}$ in spreminjali vrednosti $1^s, 2^s, \\ldots, n^s $, da $\\rho$ postane homomorfziem. Težava je, da so vrednosti v tabeli diskretne in gradientne metode optimizacije odpadejo. \n",
    "\n",
    "Rešitev je, da na prostoru funckij $S_n$ (ali pa na $\\text{fun}([n], [n])$) uvedemo verjetnostno porazdelitev $P = P(\\phi)$ in optimiziramo $P(\\rho \\text{ je homomorfizem}$.\n",
    "\n",
    "Meni se zdita smiselna dva načina. Eden je bolj strojno učenjaški, eden pa je zelo podoben iskanju upodobitev."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e8f90",
   "metadata": {},
   "source": [
    "## Matrični pristop\n",
    "Vzenimo  model $\\rho_\\phi \\colon G=<S|R> \\to \\text{dist}(\\text{fun}([n], [n]))$, ki je definiram s tem, da vsakemu generatorju $s \\in S$ dodeli matriko $\\phi_s \\in \\mathbb R^{n \\times n}$. *(Simetrično kot pri upodobitvah!!)*\n",
    "\n",
    "Matriko $\\phi_s$ pretvorimo v stohastično matriko $P_s=\\begin{bmatrix} s_{i,j} \\end{bmatrix}_{i, j = 1, \\dots, n} := \\text{softmax}_\\text{po vrsticah} (\\phi_s)$. \n",
    "\n",
    "S $P_s$ je določena porazdelitev nad $\\text{fun}([n], [n])$. Na $s \\in S$ lahko gledamo kot slučajno spremenljivko $s \\in  \\text{fun}([n], [n])$ in definiramo \n",
    "$$\n",
    "P(s(i) = j) := s_{i, j}.\n",
    "$$\n",
    "Za poljubno deterministično funckijo $f \\in \\text{fun}([n], [n])$ definiramo še \n",
    "$$\n",
    " P(s = f) = \\prod_{i=1}^n P(s(i) = f(i)) = \\prod_{i=1}^n s_{i, f(i)}.\n",
    "$$\n",
    "S tem smo definirali model $\\rho$, ki vsako matriko iz $\\{\\phi_s \\mid s \\in S\\}$ slika v svojo slučajno spremenljivko $s \\in \\text{fun}([n], [n])$. \n",
    "\n",
    "Želeli bi, da je **$P(\\rho \\text{ je homomorfizem in ima lepe lastnosti})$** čim večja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c595a86",
   "metadata": {},
   "source": [
    "### $\\mathcal L_{rel}$ - kaznujmo modele, ki niso homomomorfizmi\n",
    "Naj bo $G=<S|R>$ in $r \\in R$ beseda v generatorjih iz $R$. Na vsak generator lahko gledamo kot na slučajno funkcijo nad $[n]$. Podobno lahko tudi na $r$ gledamo kot na kompozitum svojih generatorjev. Velja še, da je matrika porazdelitve za $r$ enaka $P_r = \\begin{bmatrix} P(r(i) = j) \\end{bmatrix}_{i,j} = \\prod _{s \\in r} P_s$ produkt matrik porazdelitev generatorjev v $r$. \n",
    "\n",
    "Želimo si, da je $r$ kot slučajna funkcija skoraj zagotovo enaka identiteti, torej da je \n",
    "$$\n",
    "P(r = \\text{id}) = 1.\n",
    "$$\n",
    "Ekvivalentno: \n",
    "$$\n",
    "0 = \\log(P(r = \\text{id})) = \\log(\\prod_{i=1}^n r_{i,i}) = \\sum_{i=1}^n \\log (r_{i,j}) = \\text{trace} (\\log(P_r)),\n",
    "$$\n",
    "kjer logaritem matrike računamo po elementih.\n",
    "Za funckijo izgube lahko vzamemo\n",
    "\n",
    "$\\mathcal L_{rel} =- \\text{trace} (\\log(P_r)) =-\n",
    " \\text{trace} (\\log(\\prod_{s \\in r}  \\text{softmax}(\\phi_s)  ))$.\n",
    "\n",
    "*Na nek način gre za maximal negative likelihood*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81ea9f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameters:  tensor([[[    0.50,     0.32,     0.11],\n",
      "         [    0.49,     0.85,     0.66],\n",
      "         [    0.52,     0.51,     0.52]],\n",
      "\n",
      "        [[    0.13,     0.91,     0.05],\n",
      "         [    0.80,     0.96,     0.95],\n",
      "         [    0.45,     0.16,     0.00]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# torch \n",
    "import torch\n",
    "n = 3\n",
    "# Dn\n",
    "\n",
    "\n",
    "\n",
    "# za Dn --> Dn: \n",
    "phi = torch.tensor([[[0.19, 0.87, 0.43],\n",
    "         [0.58, 0.23, 0.97],\n",
    "         [0.57, 0.03, 1.00]],\n",
    "\n",
    "        [[0.48, 0.64, 0.04],\n",
    "         [0.47, 0.17, 0.84],\n",
    "         [0.63, 0.53, 0.74]]], requires_grad=True)\n",
    "\n",
    "\n",
    "# random : \n",
    "phi = torch.rand((2, n, n), requires_grad=True)\n",
    "\n",
    "\n",
    "generators = {\n",
    "'r' : 0, 's' :1\n",
    "}\n",
    "relations = ['r'*n, 's'*2, 'rsrs']\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "def get_P(generator, phi):\n",
    "    return softmax(phi[generators[generator]])\n",
    "\n",
    "\n",
    "\n",
    "def loss_rel(generators, relations, phi):\n",
    "    ans =torch.zeros((n,n))\n",
    "    for r in relations:\n",
    "        prod = torch.eye(n)\n",
    "        for s in r:\n",
    "            prod = prod @ softmax(phi[generators[s]])\n",
    "        prod = torch.log(prod)\n",
    "        ans += prod \n",
    "    return -ans.trace() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starting parameters: \", phi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46bfd366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1: 10.011245727539062\n",
      "Loss at step 501: 0.2076064944267273\n",
      "Loss at step 1001: 0.06668060272932053\n",
      "Loss at step 1501: 0.03319280594587326\n",
      "Loss at step 2001: 0.019616302102804184\n",
      "Loss at step 2501: 0.012690717354416847\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "n_steps = 3000\n",
    "opt = Adam([phi], lr= 0.01)\n",
    "#scheduler = StepLR(opt, step_size=30, gamma=0.1)\n",
    "\n",
    "for step in range(1, n_steps+1):\n",
    "    opt.zero_grad()\n",
    "    loss = loss_rel(generators, relations, phi)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "   # scheduler.step()\n",
    "    if step % 500 == 1:\n",
    "        print(f\"Loss at step {step}: {loss.item()}\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fbea20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1.00,     0.00,     0.00],\n",
       "         [    0.00,     1.00,     0.00],\n",
       "         [    0.00,     0.00,     1.00]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[    0.00,     1.00,     0.00],\n",
       "         [    1.00,     0.00,     0.00],\n",
       "         [    0.00,     0.00,     1.00]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = get_P('r', phi)\n",
    "S = get_P('s', phi)\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "R, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "464952d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 1, 2: 2, 3: 3}, {1: 2, 2: 1, 3: 3})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def closest_permutation_matrix(M: torch.Tensor) -> torch.Tensor:\n",
    "    # Convert to numpy for scipy\n",
    "    M_np = M.detach().numpy()\n",
    "\n",
    "    # Solve the linear sum assignment problem on the NEGATED matrix\n",
    "    # (because we want to maximize the sum, but scipy minimizes)\n",
    "    row_ind, col_ind = linear_sum_assignment(-M_np)\n",
    "\n",
    "    # Create the permutation matrix\n",
    "    n = M.size(0)\n",
    "    P = torch.zeros_like(M)\n",
    "    P[row_ind, col_ind] = 1.0\n",
    "    return P\n",
    "\n",
    "def permutation_from_matrix(X: torch.Tensor) -> torch.Tensor:\n",
    "    table =X.argmax(dim=1) + 1 \n",
    "    perm = {}\n",
    "    for i in range(X.shape[0]):\n",
    "        perm[i+1] = table[i].item()\n",
    "    return perm\n",
    "\n",
    "\n",
    "permutation_from_matrix(closest_permutation_matrix(R)), permutation_from_matrix(closest_permutation_matrix(S))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df33d7a",
   "metadata": {},
   "source": [
    "### $\\mathcal L_{perm}$ - kaznujmo modele, ki niso permutacije\n",
    "Podobno kot pri upodobitvah, ko definiramo funckijo izgube $\\mathcal L_{unit}$, ki matrike optimizira v unitarne in s tem v obrnljive, lahko tukaj pomagamo $\\mathcal L_{rel}$ s tem, da funckije \"potiskamo\" v bijekcije. \n",
    "\n",
    "Naj bo $s \\in S$ generator. Radi bi, da je $s$ kot preslikava nad $[n]$ skoraj zagotovo bijekcija, torej \n",
    "$$\n",
    "P(s \\in S_n )= 1.\n",
    "$$\n",
    "Velja pa \n",
    "$$\n",
    "P(s \\in S_n )= \\sum_{\\sigma \\in S_n} P(s = \\sigma) = \\sum_{\\sigma \\in S_n}   \\prod_{i=1}^n s_{i, \\sigma(i)}\n",
    "= \\text{Perm} (P_s).\n",
    "$$\n",
    "[Edine stohastične matrike z enotskim permanentom so permutacijske](https://math.stackexchange.com/questions/5063254/if-a-stochastic-matrix-has-unit-permanent-is-it-a-permutation-matrix), torej je \n",
    "$\n",
    "P(s \\in S_n )= 1.\n",
    "$ natantko tedaj, ko je $P_s$ permutacijska. Za stohastične matrike pa je to ekvivalentno temu, da je $P_s$ **unitarna**. \n",
    "\n",
    "Za funkcijo izgube lahko vzamemo kar funckijo izgube za unitarnost, uporabljeno na matrikah $P_s$:\n",
    "$$\n",
    "\\mathcal L_{perm} = \\sum_{s \\in S}||P_sP_s^*  - I||_F^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b79e21",
   "metadata": {},
   "source": [
    "### Avtomorfizmi grafov \n",
    "Naj bo $\\mathcal G = ([n], E)$ graf na $n$ vozljiščih in $M=\\begin{bmatrix}m_{i,j}\\end{bmatrix}$ njegova matrika sosednosti. Naš model $\\rho_\\phi$ lahko spreminjamo v avtomorfizem grafa $\\mathcal G$.\n",
    "\n",
    "Za $(i,j) \\in E$ računamo \n",
    "$$\n",
    "P(i^s \\sim j ^s) = \\sum_{k= 1}^n \\sum_{h = 1}^n s_{i, k} s_{j, h} m_{k,h} = s_j^T M s_i = (P_SMP_s^T)_{i,j}\n",
    "$$\n",
    "kjer je $P_s = \\begin{bmatrix} s_1^T \\\\ \\vdots \\\\ s_n^T \\end{bmatrix}$.\n",
    "\n",
    "Radi bi, da velja \n",
    "$\n",
    "1 = \\displaystyle\\prod_{(i,j) \\in E} P(i^s \\sim j ^s).\n",
    "$. \n",
    "Za funkcijo izgube lahko vzamemo\n",
    "$$\n",
    "\\mathcal L_{aut} = -\\sum_{i=1}^n\\sum_{j=1}^n log(s_j^T M s_i)m_{i,j}= -\\text{tr}(\\log(P_sMP_s^T) M^T),\n",
    "$$\n",
    "kjer je $\\log(SMS^T)$ izračunan po elementih."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df203259",
   "metadata": {},
   "source": [
    "Podoben premislek dela za poljubne morfizme grafov. Naj bo $M$ matrika sosednosti enega grafa in $N$ matrika sosednosti drugega. Velja $P(i^s \\sim j ^s) = \\sum_{k= 1}^n \\sum_{h = 1}^n s_{i, k} s_{j, h} n_{k,h} = s_j^T N s_i$. Za loss izberemo \n",
    "$$\n",
    "\\mathcal L_{aut} = -\\sum_{i=1}^n\\sum_{j=1}^n log(s_j^T N s_i)m_{i,j}= -\\text{tr}(\\log(P_sNP_s^T) M^T)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd795bb2",
   "metadata": {},
   "source": [
    "### Avtomorfizmi grafov - brez group\n",
    "Verjetno je bolj smiselno iskati le avtomorfizme grafov. Vse isto, le pozabiš na $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20b236",
   "metadata": {},
   "source": [
    "Demo: poiščimo kak avtomorfizem preporostega grafa:\n",
    "![Demo graf](demo_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 5), (2, 5), (3, 4), (4, 5)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def compose(p, q):\n",
    "    \"\"\"Return the composition p ∘ q (first q, then p) for permutations\n",
    "    stored as tuples whose i-th entry is the image of i+1.\"\"\"\n",
    "    return tuple(p[q[i] - 1] for i in range(len(p)))\n",
    "\n",
    "def inverse(p):\n",
    "    \"\"\"Inverse of a permutation given in tuple form.\"\"\"\n",
    "    inv = [0] * len(p)\n",
    "    for i, x in enumerate(p):\n",
    "        inv[x - 1] = i + 1\n",
    "    return tuple(inv)\n",
    "\n",
    "def cayley_Sn_edges(n: int):\n",
    "    \"\"\"\n",
    "    Return the edge list of the (undirected) Cayley graph of S_n\n",
    "    with generators a = (1 2) and b = (1 2 … n).  Vertices are\n",
    "    indexed 0 … n!−1 in lexicographic order of permutations.\n",
    "    Each edge is an ordered pair (i, j) with i < j.\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        raise ValueError(\"n must be at least 2\")\n",
    "\n",
    "    # all permutations of 1…n in lexicographic order\n",
    "    perms = list(itertools.permutations(range(1, n + 1)))\n",
    "    index = {p: k for k, p in enumerate(perms)}\n",
    "\n",
    "    # generators\n",
    "    a = tuple([2, 1, *range(3, n + 1)])          # (1 2)\n",
    "    b = tuple([*range(2, n + 1), 1])             # (1 2 … n)\n",
    "    b_inv = inverse(b)                           # (1 n … 2)\n",
    "\n",
    "    edges = set()\n",
    "    for p in perms:\n",
    "        i = index[p]\n",
    "        for g in (a, b, b_inv):\n",
    "            j = index[compose(g, p)]\n",
    "            if i < j:\n",
    "                edges.add((i, j))\n",
    "\n",
    "    # return a list sorted for reproducibility\n",
    "    return sorted(edges)\n",
    "\n",
    "cayley_Sn_edges(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede6cc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "906817f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial matrix:  tensor([[0.13, 0.38, 0.72, 0.33],\n",
      "        [0.45, 0.95, 0.30, 0.66],\n",
      "        [0.58, 0.05, 0.37, 0.20],\n",
      "        [0.53, 0.62, 0.80, 0.24]], requires_grad=True)\n",
      "Loss at step 1: 8.085267066955566\n",
      "Loss at step 501: 1.400468111038208\n",
      "Loss at step 1001: 1.3016853332519531\n",
      "Loss at step 1501: 1.2764768600463867\n",
      "Loss at step 2001: 1.2658944129943848\n",
      "Loss at step 2501: 1.2603845596313477\n"
     ]
    }
   ],
   "source": [
    "# torch\n",
    "\n",
    "m=6\n",
    "m=4\n",
    "# prepare small graph\n",
    "edges = [(0,1), (0,2), (1,2), (2, 3)]\n",
    "\n",
    "#edges = cayley_Sn_edges(3)\n",
    "M = torch.zeros((m,m))\n",
    "for i, j in edges:\n",
    "    M[i,j] = 1\n",
    "    M[j, i] = 1\n",
    "\n",
    "# primer, ko skonvergiramo:\n",
    "Q = torch.tensor([[0.13, 0.34, 0.38, 0.23],\n",
    "        [0.71, 0.22, 0.98, 0.84],\n",
    "        [0.25, 0.52, 0.71, 0.59],\n",
    "        [0.85, 0.93, 0.88, 0.64]], requires_grad=True)\n",
    "\n",
    "\n",
    "# input:\n",
    "Q = torch.rand((m,m), requires_grad=True)\n",
    "\n",
    "def loss_aut(Q, M):\n",
    "    P = softmax(Q)\n",
    "    ans = P @ M @ P.transpose(0,1)\n",
    "    ans = torch.log(ans )\n",
    "    ans = ans @ M.transpose(0,1)\n",
    "    return -ans.trace()\n",
    "\n",
    "def loss_bijection(Q):\n",
    "    P = softmax(Q)\n",
    "    return torch.linalg.matrix_norm( P@ P.transpose(0,1) - torch.eye(P.shape[0]))**2\n",
    "\n",
    "\n",
    "n_steps_aut = 3000\n",
    "opt_aut = Adam([Q], lr=0.01)\n",
    "\n",
    "print(\"Initial matrix: \", Q)\n",
    "\n",
    "for step in range(1, n_steps_aut+1):\n",
    "    opt_aut.zero_grad()\n",
    "    loss =loss_aut(Q, M) + loss_bijection(Q)\n",
    "    loss.backward()\n",
    "    opt_aut.step()\n",
    "    if step % 500 == 1:\n",
    "        print(f\"Loss at step {step}: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d7587a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    0.00,     0.00,     1.00,     0.00],\n",
       "        [    0.00,     1.00,     0.00,     0.00],\n",
       "        [    1.00,     0.00,     0.00,     0.00],\n",
       "        [    0.00,     0.50,     0.50,     0.00]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.imshow(softmax(Q).detach().numpy(), cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(\"Q matrix\")\n",
    "plt.show()\n",
    "softmax(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44207700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3, 2: 2, 3: 1, 4: 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_from_matrix(closest_permutation_matrix(Q.transpose(0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c7b92",
   "metadata": {},
   "source": [
    "## Strojnoučenjaški pristop\n",
    "Namesto, da optimiziramo model $\\rho \\colon G \\to \\text{fun}([n], [n])$, naredimo model, ki že v začetku slika v $S_n$. (Podobno, kot smo pri upodobitvah naredili model, ki direktno slika v O(2)).\n",
    "\n",
    "Velja $S_n = <a, b | R>$. Vsaka permutacija je torej beseda v $\\{a, b\\}$. \n",
    "\n",
    "Besede lahko gradimo rekurzivno. Definiramo model $M : S_n \\to \\text{bernulli}\\{a, b\\}$, ki za vsako permutacijo $\\pi \\in S_n$ vrne vektor verjetnosti  $[P(a | \\pi), P(b | \\pi), P(id | \\pi)]$. S pomočjo tega modela lahko gradimo markovsko verigo:\n",
    "- začneš z identiteto $\\pi_0 = \\text{id}$\n",
    "- vsak korak iz porazdelitve  $[P(a | \\pi_i), P(b | \\pi_i), P(id | \\pi)]$ vzorčiš generator $g \\in \\{a, b\\}$. Če je $g$ identiteta, končaš in vrneš $\\pi _i$, sicer pa nastaviš $\\pi_{i+1} = \\text{perm}(\\pi_i \\circ g)$,\n",
    "kjer je $\\text{perm}$ preslikava, ki besede slika v permutacije, ki jih besede predstavljajo (to je boljše, kot da model za vhod vzame besedo - besede so ppoljubno dolge in redundantne, permutacija pa je  vektor dimenzije $n$).\n",
    "\n",
    "Za poljubno funckijo izgube $\\mathcal L$ nad preslikavami  $G \\mapsto S_n$ lahko minimaliziramo $E[\\mathcal L (\\rho)]$, kjer je $\\rho$ zgoraj opisani slučjani proces.\n",
    "\n",
    "Ta pristop je kul, ker se je z njim (v obliki $S \\to aS  |bs | 1$) vse začelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a36eb9f",
   "metadata": {},
   "source": [
    "# Kaj vse še lahko iščemo\n",
    "## Poti na grafih z utežmi:\n",
    "- najcenejša/najdražja pot, ki gre čez cel graf (to je lih funkcija)\n",
    "- EULERJEVE POTI (in hamiltonove) - to so tud lih funkcije\n",
    "- poljubne poti - to niso več funkcije, ampak besede na vozljiščih. mejbi glej drugi način? Če maš fkisno dolžino poti, pa lah delaš skor krkol\n",
    "### Grafi\n",
    "- mogoče lahko iščeš grafe z nekimi lastnostmi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
